# 回歸分析
```
https://www.w3schools.com/python/python_ml_linear_regression.asp
```
## 先認識資料集的特色 ==> scatter diagram
```
import matplotlib.pyplot as plt

x = [5,7,8,7,2,17,2,9,4,11,12,9,6]
y = [99,86,87,88,111,86,103,87,94,78,77,85,86]

plt.scatter(x, y)
plt.show()
```
## 線性回歸 ==> 使用 scipy 模組
```
import matplotlib.pyplot as plt
from scipy import stats

x = [5,7,8,7,2,17,2,9,4,11,12,9,6]
y = [99,86,87,88,111,86,103,87,94,78,77,85,86]

slope, intercept, r, p, std_err = stats.linregress(x, y)

def myfunc(x):
  return slope * x + intercept

mymodel = list(map(myfunc, x))

plt.scatter(x, y)
plt.plot(x, mymodel)
plt.show()
```
### stats.linregress()
```
https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html

scipy.stats.linregress(x, y=None)
Calculate a linear least-squares regression for two sets of measurements.


函數執行後的回傳值(Returns) ==>
resultLinregressResult instance
The return value is an object with the following attributes:

slopefloat ==> Slope of the regression line.

interceptfloat ==> Intercept of the regression line.

rvaluefloat ==> Correlation coefficient.

pvaluefloat ==>
Two-sided p-value for a hypothesis test 
whose null hypothesis is that the slope is zero, 
using Wald Test with t-distribution of the test statistic.

stderrfloat ==> Standard error of the estimated slope (gradient), 
                under the assumption of residual normality.

intercept_stderrfloat ==> Standard error of the estimated intercept, 
                under the assumption of residual normality.
```
```
原始碼分析 ==>
https://github.com/scipy/scipy/blob/v1.6.3/scipy/stats/_stats_mstats_common.py#L16-L187

def linregress(x, y=None):
    """
    說明文字比程式碼還多
    """    
    return LinregressResult(slope=slope, intercept=intercept, rvalue=r,
                            pvalue=prob, stderr=slope_stderr,
                            intercept_stderr=intercept_stderr)
```
```
原始碼分析 ==>
https://github.com/scipy/scipy/blob/v1.6.3/scipy/stats/_stats_mstats_common.py#L16-L187

"""
    Calculate a linear least-squares regression for two sets of measurements.
    Parameters
    ----------
    x, y : array_like
        Two sets of measurements.  Both arrays should have the same length.  If
        only `x` is given (and ``y=None``), then it must be a two-dimensional
        array where one dimension has length 2.  The two sets of measurements
        are then found by splitting the array along the length-2 dimension. In
        the case where ``y=None`` and `x` is a 2x2 array, ``linregress(x)`` is
        equivalent to ``linregress(x[0], x[1])``.
    Returns
    -------
    result : ``LinregressResult`` instance
        The return value is an object with the following attributes:
        slope : float
            Slope of the regression line.
        intercept : float
            Intercept of the regression line.
        rvalue : float
            Correlation coefficient.
        pvalue : float
            Two-sided p-value for a hypothesis test whose null hypothesis is
            that the slope is zero, using Wald Test with t-distribution of
            the test statistic.
        stderr : float
            Standard error of the estimated slope (gradient), under the
            assumption of residual normality.
        intercept_stderr : float
            Standard error of the estimated intercept, under the assumption
            of residual normality.
    See Also
    --------
    scipy.optimize.curve_fit :
        Use non-linear least squares to fit a function to data.
    scipy.optimize.leastsq :
        Minimize the sum of squares of a set of equations.
    Notes
    -----
    Missing values are considered pair-wise: if a value is missing in `x`,
    the corresponding value in `y` is masked.
    For compatibility with older versions of SciPy, the return value acts
    like a ``namedtuple`` of length 5, with fields ``slope``, ``intercept``,
    ``rvalue``, ``pvalue`` and ``stderr``, so one can continue to write::
        slope, intercept, r, p, se = linregress(x, y)
    With that style, however, the standard error of the intercept is not
    available.  To have access to all the computed values, including the
    standard error of the intercept, use the return value as an object
    with attributes, e.g.::
        result = linregress(x, y)
        print(result.intercept, result.intercept_stderr)
    Examples
    --------
    >>> import matplotlib.pyplot as plt
    >>> from scipy import stats
    Generate some data:
    >>> np.random.seed(12345678)
    >>> x = np.random.random(10)
    >>> y = 1.6*x + np.random.random(10)
    Perform the linear regression:
    >>> res = stats.linregress(x, y)
    Coefficient of determination (R-squared):
    >>> print(f"R-squared: {res.rvalue**2:.6f}")
    R-squared: 0.735498
    Plot the data along with the fitted line:
    >>> plt.plot(x, y, 'o', label='original data')
    >>> plt.plot(x, res.intercept + res.slope*x, 'r', label='fitted line')
    >>> plt.legend()
    >>> plt.show()
    Calculate 95% confidence interval on slope and intercept:
    >>> # Two-sided inverse Students t-distribution
    >>> # p - probability, df - degrees of freedom
    >>> from scipy.stats import t
    >>> tinv = lambda p, df: abs(t.ppf(p/2, df))
    >>> ts = tinv(0.05, len(x)-2)
    >>> print(f"slope (95%): {res.slope:.6f} +/- {ts*res.stderr:.6f}")
    slope (95%): 1.944864 +/- 0.950885
    >>> print(f"intercept (95%): {res.intercept:.6f}"
    ...       f" +/- {ts*res.intercept_stderr:.6f}")
    intercept (95%): 0.268578 +/- 0.488822
    """
```
### SciPy
```
https://www.scipy.org/

SciPy is a free and open-source Python library used 
for scientific computing and technical computing. 

SciPy contains modules for optimization, linear algebra, 
integration, interpolation, special functions, FFT, 
signal and image processing, ODE solvers 
and other tasks common in science and engineering.
```
### 作業
```
scipy 實測
```

### 作業 ==> SymPy實測
```
https://www.sympy.org/en/index.html
```
